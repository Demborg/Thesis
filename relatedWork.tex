% Created 2018-02-08 tor 16:53
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\newcommand{\bibentry}[1]{\cite{#1}}
\author{Axel Demborg \texttt{demborg@kth.se}}
\date{\today}
\title{Related Work: Network Compression}
\hypersetup{
 pdfauthor={Axel Demborg \texttt{demborg@kth.se}},
 pdftitle={Related Work: Network Compression},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.3.1 (Org mode 9.1.6)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section*{Related work}
\label{sec:org7a19563}
Convolutional Neural Networks (CNN) where first introduced in 1998 \bibentry{lecun1998gradient} and since then larger and larger CNNs have slowly become the state of the art method for most areas of computer vision. Notably \emph{AlexNet} \bibentry{krizhevsky2012imagenet} in 2012 proved that that deep CNNs could be used for high resolution image classification by beating the previous state of the art\bibentry{sanchez2011high} on the \emph{ImageNet} classification challenge\bibentry{deng2009imagenet}. To do this \emph{AlexNet} uses 60 million parameters and 650,000 neurons and training of the network was only made feasible by the use of multiple graphical processing units (GPUs)\bibentry{krizhevsky2012imagenet}. 

In the areas of object detection and semantic segmentation it was \emph{Regions with CNN features} (\emph{R-CNN})\bibentry{girshick2014rich} that in 2014 first showed that CNNs could be successfully be applied to these fields by significantly improving over the previous state of the art in object detection \bibentry{ren2013histograms} and after minor modifications matching the performance of the state of the art in semantic segmentation\bibentry{carreira2012semantic} with a system not specifically built for the task. For object detection \emph{R-CNN} works as a hybrid system with \emph{selective search}\bibentry{uijlings2013selective} producing proposals for object regions and a CNN, pre-trained on \emph{ImageNet}\bibentry{deng2009imagenet} and fine-tuned for region classification, generating fixed length features for each region, finally classifying each region by running class specific \emph{support vector machines}\bibentry{boser1992training} on these features. Some issues with \emph{R-CNN} are that it requires a multistage training, training the CNN to give good features and training the SVMs for classification, and that it is slow, for training but most notably at inference where one image is processed in 47s. These problems are addressed with further work resulting in \emph{Fast R-CNN} \bibentry{girshick2015fast} where the CNN isn't run once per proposed region but instead once for the entire network generating a convolutional feature map that is then pooled with a region of interest (RoI) pooling layer to produce a feature vector for each region. These feature vectors are then feed into a fully connected neural network with two sibling output layers that perform both classification and bounding box refinement in parallel. With these improvements \emph{Fast R-CNN} achieves faster inference and higher accuracy than its predecessors and does so with a arguably much more elegant design. Even though \emph{Fast R-CNN} improved speed significantly it was nowhere near real-time performance, further performance improvements were introduced with \emph{Faster R-CNN}\bibentry{ren2015faster} where \emph{selective search} for region proposals is replaced with Region Proposal Networks, fully convolutional neural networks that take as input the convolutional feature maps as described from \emph{Fast R-CNN} and outputs region proposals. Since this approach for region proposals shares most of its computation with the classification network the region proposals are practically free and frame rates of 5fps are achievable. The region proposal networks not only speed up computation but also prove to give better accuracy region proposals and thus raise over all accuracy in the system as well\bibentry{ren2015faster}. Even further improvements to this framework was achieved with the introduction of \emph{Mask R-CNN}\bibentry{he2017mask} which expands upon \emph{Faster R-CNN} by adding a third branch for a segmentation mask besides the branches for bounding box refinement and classification making the system able to predict not only the general bounding box of items in the image but also which exact pixels belong to the object. Since segmentation is a pixel-by-pixel prediction problem \emph{Mask R-CNN} replaces the spatially quantizing RoIPool operation from \emph{Fast R-CNN} with a quantization-free layer called RoIAllign.

Some parallel work on semantic segmentation of images resulted in \emph{SegNet}\bibentry{badrinarayanan2015segnet}, a fully convolutional encoder-decoder network. Here the encoder network encodes the input image down into a lower dimensional feature space while keeping storing the indices of the max pooling operations. The low dimensional representations are then run through a decoder network which is architecturally a mirror image of the encoder network but where the max pooling operations have been replaced with upsampling layers that use the stored indices from the corresponding pooling layers to maintain the granularity of the images. The final layer in the network is a softmax and hence the outputs are the probabilities of each pixel belong to each class.
Continued work on segmentation utilizes blocks of so called \emph{DenseNets}\bibentry{huang2017densely}, CNNs where every layer is connected to every layer after it enabling the training of really deep network architectures by alleviating the vanishing gradient problem and promoting feature reuse between the layers. By using these \emph{DensNets} in a very deep encoder-decoder structure where skip connections restore image granularity during upsampling the state of the art in image segmentation has been pushed even further \bibentry{jegou2017one} while still reducing the amount of parameters required for the models by a factor 10 as compared to the previous state of art.

Despite their impressive performance on a wide range of problems neural networks are still prohibited from running locally on mobile devices with slow processors, limited power envelopes or limited memory due to their large size and big computational load. For example modern neural networks can't fit on the on-chip SRAM cache and instead they have to reside in the much more power hungry off-chip DRAM memory making applications up to 100 times more power consuming\bibentry{han2015learning}. Due to these limitations many applications of neural networks for mobile use cases are forced to be run on the cloud which requires steady network connections and incurs delays, both of which may be intolerable for real-time mobile applications, self driving cars and robotics.

\bibliographystyle{plain}
\bibliography{bibliography} 
\end{document}